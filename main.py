# -*- coding: utf-8 -*-
"""Seq2seq_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TEODKPUK5VcSTzU-cmDfDfqszYKKrjj6
"""

!pip install spacy==3.0.6
!python -m spacy download hi_core_news_sm

!pip install hi_core_news_sm

!python -m spacy download en_core_web_sm

!pip install torchtext==0.10.0

!pip install torch==1.8.0 torchtext==0.9.0

!pip install -c pytorch torchtext==0.8

!pip install python-requests

!pip install --upgrade setuptools

!pip uninstall requests
!pip install requests

!pip install torch

# Set the random seed
SEED = 5678
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
torch.backends.cudnn.deterministic = True

!python -m spacy download xx_ent_wiki_sm

# Download and load the Spacy models
spacy_hi = spacy.load('xx_ent_wiki_sm')
spacy_en = spacy.load('en_core_web_sm')

def eng_tokenizer(text):
    tokens = []
    for tok in spacy_en.tokenizer(text):
        tokens.append(tok.text)
    return tokens[::-1]

def hindi_tokenizer(text):
    tokens1 = []
    for tok in spacy_hi.tokenizer(text):
        tokens1.append(tok.text)
    return tokens1[::-1]

# creating field objects
source_field = Field(tokenize='spacy', tokenizer_language='en_core_web_sm', lower=True, init_token='<sos>', eos_token='<eos>')
target_field = Field(tokenize='spacy', tokenizer_language='xx_ent_wiki_sm', init_token='<sos>', eos_token='<eos>')

# Load the data into a TabularDataset object
from torchtext.legacy import data
train_data = data.TabularDataset(
               path='/content/hi.translit.sampled.train.tsv',
               format='tsv',
               fields=[('src', source_field), ('trg', target_field)],
               skip_header=True)

from torchtext.legacy import data
test_data = data.TabularDataset(
               path='/content/hi.translit.sampled.test.tsv',
               format='tsv',
               fields=[('src', source_field), ('trg', target_field)],
               skip_header=True)

from torchtext.legacy import data
valid_data = data.TabularDataset(
               path='/content/hi.translit.sampled.dev.tsv',
               format='tsv',
               fields=[('src', source_field), ('trg', target_field)],
               skip_header=True)

def build_vocab(train_data, test_data):
    source_field.build_vocab(train_data, min_freq=2)
    target_field.build_vocab(train_data, min_freq=2)

build_vocab(train_data, test_data)
print(f'lengh of SRC vocab is {len(source_field.vocab)}')
print(f'lengh of TRG vocab is {len(target_field.vocab)}')

def create_iterators(train_data, test_data, valid_data, batch_size, device):
    train_iterator, test_iterator = data.BucketIterator.splits(
        datasets=(train_data, test_data),
        batch_size=batch_size,
        sort_key=lambda x: len(x.src),
        shuffle=True,
        device=device
    )
    valid_iterator = data.BucketIterator(
        dataset=valid_data,
        batch_size=batch_size,
        sort_key=lambda x: len(x.src),
        shuffle=True,
        device=device
    )
    return train_iterator, test_iterator, valid_iterator

device = 'cuda' if torch.cuda.is_available() else 'cpu'
batch_size1 = 32

train_iterator, test_iterator , valid_iterator = create_iterators(train_data, test_data, valid_data, batch_size1, device)

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader

# define device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


# define model
class Encoder(nn.Module):
    def __init__(self, input_dim, emb_dim, hidden_dim, num_layers, dropout):
        super().__init__()
        self.embedding = nn.Embedding(input_dim, emb_dim)
        self.rnn = nn.LSTM(emb_dim, hidden_dim, num_layers, dropout=dropout)

    def forward(self, src):
        embedded = self.embedding(src)
        outputs, (hidden, cell) = self.rnn(embedded)
        return hidden, cell


class Decoder(nn.Module):
    def __init__(self, output_dim, emb_dim, hidden_dim, num_layers, dropout):
        super().__init__()
        self.output_dim = output_dim  # add output_dim attribute
        self.embedding = nn.Embedding(output_dim, emb_dim)
        self.rnn = nn.LSTM(emb_dim, hidden_dim, num_layers, dropout=dropout)
        self.fc_out = nn.Linear(hidden_dim, output_dim)

    def forward(self, input, hidden, cell):
        input = input.unsqueeze(0)
        embedded = self.embedding(input)
        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))
        prediction = self.fc_out(output.squeeze(0))
        return prediction, hidden, cell


class Seq2Seq(nn.Module):
    def __init__(self, encoder, decoder):
        super().__init__()
        self.encoder = encoder
        self.decoder = decoder

    def forward(self, src, trg, teacher_forcing_ratio=0.5):
        batch_size = trg.shape[1]
        trg_len = trg.shape[0]
        trg_vocab_size = self.decoder.output_dim

        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(device)

        hidden, cell = self.encoder(src)

        input = trg[0,:]

        for t in range(1, trg_len):
            output, hidden, cell = self.decoder(input, hidden, cell)
            outputs[t] = output
            teacher_force = random.random() < teacher_forcing_ratio
            top1 = output.argmax(1)
            input = trg[t] if teacher_force else top1

        return outputs

# define hyperparameters
input_dim = len(source_field.vocab)
output_dim = len(target_field.vocab)
emb_dim = 16
hidden_dim = 16
num_layers = 1
dropout = 0.5
learning_rate = 0.001
num_epochs = 10

encoder = Encoder(input_dim, emb_dim, hidden_dim, num_layers, dropout).to(device)
decoder = Decoder(output_dim, emb_dim, hidden_dim, num_layers, dropout).to(device)
model = Seq2Seq(encoder, decoder).to(device)

# define optimizer and loss function
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
criterion = nn.CrossEntropyLoss()

def init_weights(m):
    for name, param in m.named_parameters():
        nn.init.uniform_(param.data, -0.08, 0.08)

def initialize_model_weights(model, max_tries=10):
    num_tries = 0
    while num_tries < max_tries:
        try:
            model.apply(init_weights)
            return
        except:
            num_tries += 1
    print("Failed to initialize model weights after {} tries".format(max_tries))

initialize_model_weights(model)

# define train and evaluation functions
def train(model, iterator, optimizer, criterion, clip=None):
    model.train()
    epoch_loss = 0
    for batch in iterator:
        src,trg= batch.src, batch.trg
        optimizer.zero_grad()
        src = src.to(device)
        trg = trg.to(device)
        output = model(src, trg)
        output = output[1:].view(-1, output.shape[-1])
        trg = trg[1:].view(-1)
        loss = criterion(output, trg)
        loss.backward()
        if clip:
            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)
        optimizer.step()
        epoch_loss += loss.item()
    return epoch_loss / len(iterator)

def evaluate(model, iterator, criterion):
    model.eval()
    epoch_loss = 0
    with torch.no_grad():
        for batch in iterator:
            src, trg = batch.src, batch.trg
            src = src.to(device)
            trg = trg.to(device)
            output = model(src, trg, teacher_forcing_ratio=0.0) # turn off teacher forcing
            output = output[1:].view(-1, output.shape[-1])
            trg = trg[1:].view(-1)
            loss = criterion(output, trg)
            epoch_loss += loss.item()
    return epoch_loss / len(iterator)

TRG_PAD_IDX = target_field.vocab.stoi[target_field.pad_token]

def calculate_accuracy(model, iterator):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for batch in iterator:
            src, trg = batch.src, batch.trg
            src = src.to(device)
            trg = trg.to(device)
            output = model(src, trg, teacher_forcing_ratio=0.0)
            output_dim = output.shape[-1]
            output = output[1:].view(-1, output_dim)
            trg = trg[1:].view(-1)
            predictions = torch.argmax(output, dim=1)
            mask = (trg != TRG_PAD_IDX)
            correct += (predictions == trg).sum().item()
            total += mask.sum().item()
    return correct / total

import pandas as pd
import matplotlib.pyplot as plt
def train_loop(model, train_iterator, test_iterator, optimizer, criterion, num_epochs, print_every=1, plot_every=1):
    train_loss_list = []
    test_loss_list = []
    accuracy_list = []
    epoch_list = []
    for epoch in range(num_epochs):
        train_loss = train(model, train_iterator, optimizer, criterion)
        test_loss = evaluate(model, test_iterator, criterion)
        train_loss_list.append(train_loss)
        test_loss_list.append(test_loss)
        if (epoch+1) % print_every == 0:
            print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Test Loss: {test_loss:.3f}')
        if (epoch+1) % plot_every == 0:
            acc = calculate_accuracy(model, test_iterator)
            print(f'Epoch: {epoch+1:02} | test Acc: {acc*100:.2f}%')
            accuracy_list.append(acc)
            epoch_list.append(epoch+1)

    # create dataframe from the results
    results_df = pd.DataFrame({'train_loss': train_loss_list, 'test_loss': test_loss_list, 'accuracy': accuracy_list}, index=epoch_list)

    # plot the results
    fig, ax = plt.subplots(figsize=(10,6))
    ax2 = ax.twinx()
    ax.plot(results_df.index, results_df.train_loss, label='train loss', color='blue')
    ax.plot(results_df.index, results_df.test_loss, label='test loss', color='orange')
    ax2.plot(results_df.index, results_df.accuracy, label='accuracy', color='green')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Loss')
    ax2.set_ylabel('Accuracy')
    ax.legend(loc='upper left')
    ax2.legend(loc='upper right')
    plt.show()

    # print the correlation table
    corr_table = results_df.corr()
    print('\nCorrelation Table:')
    print(corr_table)

    return train_loss_list, test_loss_list, accuracy_list

num_epochs = 10
train_loss_list, test_loss_list, accuracy_list = train_loop(model, train_iterator, test_iterator, optimizer, criterion, num_epochs, print_every=1, plot_every=1)

# validation loss
validation_loss = evaluate(model, valid_iterator, criterion)
validation_loss

# Validation accuracy
validation_accuracy = calculate_accuracy(model, valid_iterator)
validation_accuracy

"""# QUES-1(b)with different hyperparameters"""

# define hyperparameters
input_dim = len(source_field.vocab)
output_dim = len(target_field.vocab)
emb_dim = 64
hidden_dim = 64
num_layers = 3
dropout = 0.5
learning_rate = 0.001
num_epochs = 10

encoder = Encoder(input_dim, emb_dim, hidden_dim, num_layers, dropout).to(device)
decoder = Decoder(output_dim, emb_dim, hidden_dim, num_layers, dropout).to(device)
model = Seq2Seq(encoder, decoder).to(device)

# define optimizer and loss function
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
criterion = nn.CrossEntropyLoss()

num_epochs = 10
train_loss_list, test_loss_list, accuracy_list = train_loop(model, train_iterator,test_iterator, optimizer, criterion, num_epochs, print_every=1, plot_every=1)

# validation loss
validation_loss = evaluate(model, valid_iterator, criterion)
validation_loss

# Validation accuracy
validation_accuracy = calculate_accuracy(model, valid_iterator)
validation_accuracy

"""# BY adding one attention layer in model"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import random


# define device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


class Encoder(nn.Module):
    def __init__(self, input_dim, emb_dim, hidden_dim, num_layers, dropout):
        super().__init__()
        self.embedding = nn.Embedding(input_dim, emb_dim)
        self.rnn = nn.LSTM(emb_dim, hidden_dim, num_layers, dropout=dropout)

    def forward(self, src):
        embedded = self.embedding(src)
        outputs, (hidden, cell) = self.rnn(embedded)
        return outputs, hidden, cell
        #print(encoder_outputs.shape[1])

class Attention(nn.Module):
    def __init__(self, enc_hidden_dim, dec_hidden_dim):
        super().__init__()
        self.attn = nn.Linear(enc_hidden_dim + dec_hidden_dim, dec_hidden_dim)
        self.v = nn.Linear(dec_hidden_dim, 1, bias=False)

    def forward(self, hidden, encoder_outputs):
        # hidden = [batch_size, dec_hidden_dim]
        # encoder_outputs = [src_len, batch_size, enc_hidden_dim]

        batch_size = encoder_outputs.shape[1]
        src_len = encoder_outputs.shape[0]

        # repeat decoder hidden state src_len times
        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)
        #print("Shape of encoder_outputs: ", encoder_outputs.shape)
        #print("Shape of hidden: ", hidden.shape)

        # concatenate encoder outputs and decoder hidden state

        energy = torch.tanh(self.attn(torch.cat((encoder_outputs, hidden), dim=2)))

        # calculate attention weights
        attention = torch.softmax(self.v(energy).squeeze(2), dim=1)

        # calculate attention vector
        attention_vector = torch.bmm(attention.unsqueeze(1), encoder_outputs.transpose(0, 1)).squeeze(1)

        return attention_vector, attention


class Decoder(nn.Module):
    def __init__(self, output_dim, emb_dim, enc_hidden_dim, dec_hidden_dim, num_layers, dropout, attention):
        super().__init__()
        self.output_dim = output_dim
        self.embedding = nn.Embedding(output_dim, emb_dim)
        self.rnn = nn.LSTM(enc_hidden_dim + emb_dim, dec_hidden_dim, num_layers, dropout=dropout)
        self.fc_out = nn.Linear(dec_hidden_dim, output_dim)
        self.attention = attention

    def forward(self, input, hidden, cell, encoder_outputs):
        # input = [batch_size]
        # hidden = [num_layers, batch_size, dec_hidden_dim]
        # cell = [num_layers, batch_size, dec_hidden_dim]
        # encoder_outputs = [src_len, batch_size, enc_hidden_dim]

        input = input.unsqueeze(0)
        embedded = self.embedding(input)
        attention_vector, attention = self.attention(hidden[-1], encoder_outputs)
        rnn_input = torch.cat((embedded, attention_vector.unsqueeze(0)), dim=2)
        output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))
        prediction = self.fc_out(output.squeeze(0))
        return prediction, hidden, cell, attention

class Seq2Seq(nn.Module):
    def __init__(self, encoder, decoder):
        super().__init__()
        self.encoder = encoder
        self.decoder = decoder

    def forward(self, src, trg, teacher_forcing_ratio=0.5):
        # src = [src_len, batch_size]
        # trg = [trg_len, batch_size]

        trg_len, batch_size = trg.shape
        trg_vocab_size = self.decoder.output_dim

        # tensor to store decoder outputs
        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(device)

        # encode the source sequence
        encoder_outputs, hidden, cell = self.encoder(src)

        # use the <sos> token as the first input to the decoder
        input = trg[0, :]

        # loop over the target sequence
        for t in range(1, trg_len):
            # pass the input, previous hidden state and previous cell state
            # through the decoder
            output, hidden, cell, _ = self.decoder(input, hidden, cell, encoder_outputs)

            # add the decoder output to the outputs tensor
            outputs[t] = output

            # decide whether to use teacher forcing or not
            teacher_force = random.random() < teacher_forcing_ratio

            # get the highest predicted token from our predictions
            top1 = output.argmax(1)

            # if teacher forcing, use the actual next token as the next input
            # otherwise use the predicted token
            input = trg[t] if teacher_force else top1

        return outputs

# define hyperparameters
input_dim = len(source_field.vocab)
output_dim = len(target_field.vocab)
emb_dim = 16
hidden_dim = 16
num_layers = 3
dropout = 0.5
learning_rate = 0.001
num_epochs = 10

encoder = Encoder(input_dim, emb_dim, hidden_dim, num_layers, dropout).to(device)
attention = Attention(hidden_dim, hidden_dim)
decoder = Decoder(output_dim, emb_dim, hidden_dim, hidden_dim, num_layers, dropout, attention).to(device)
model = Seq2Seq(encoder, decoder).to(device)

# define optimizer and loss function
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
criterion = nn.CrossEntropyLoss()

device = 'cuda' if torch.cuda.is_available() else 'cpu'
batch_size = 3

train_iterator, test_iterator,valid_iterator = create_iterators(train_data, test_data,valid_data, batch_size, device)

num_epochs = 10
train_loss_list, test_loss_list, accuracy_list = train_loop(model, train_iterator, test_iterator, optimizer, criterion, num_epochs, print_every=1, plot_every=1)

